<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CAMEL-Bench: A Comprehensive Arabic LMM Benchmark</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            text-align: center;
        }
        h1 {
            font-size: 36px;
            font-weight: bold;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        h1 img {
            width: 50px;
            margin-right: 20px;
        }
        p.abstract {
            font-size: 18px;
            margin: 20px auto;
            max-width: 600px;
        }
        #pie-chart {
            width: 600px;
            height: 400px;
            margin: 0 auto;
        }
        .bar-chart {
            width: 400px;
            height: 300px;
            display: inline-block;
            margin: 20px;
        }
        .chart-grid {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            max-width: 1600px;
            margin: 0 auto;
        }
    </style>
</head>
<body>

    <!-- Logo and Title -->
    <h1>
        <img src="CAMEL.png" alt="Logo"> CAMEL-Bench: A Comprehensive Arabic LMM Benchmark
    </h1>

    <!-- Abstract Text -->
    <p class="abstract">
        CAMEL-Bench is a comprehensive evaluation benchmark designed for Arabic multimodal models, representing over 400 million speakers.<br><br>
        It spans eight diverse domains and 38 sub-domains, including multi-image understanding, complex visual perception, handwritten document analysis, video understanding, medical imaging, plant disease detection, and remote sensing-based land use analysis. <br>
CAMEL-Bench consists of 29,036 manually verified questions to ensure reliable model evaluation. <br>
        Our analysis highlights the need for significant improvement in both open-source and closed-source models, with GPT-4 scoring 62%. The benchmark will be made publicly available.
    </p>

    <!-- Pie Chart -->
    <div id="pie-chart"></div>

    <!-- Bar Charts -->
    <div class="chart-grid">
        <div id="bar-chart-1" class="bar-chart"></div>
        <div id="bar-chart-2" class="bar-chart"></div>
        <div id="bar-chart-3" class="bar-chart"></div>
        <div id="bar-chart-4" class="bar-chart"></div>
        <div id="bar-chart-5" class="bar-chart"></div>
        <div id="bar-chart-6" class="bar-chart"></div>
        <div id="bar-chart-7" class="bar-chart"></div>
        <div id="bar-chart-8" class="bar-chart"></div>
    </div>

    <script>
        // Data for Pie Chart
        var pieData = [{
            values: [14251, 7931, 2820, 765, 1285, 506, 769, 709],
            labels: [
                'Multimodal Und. & Reasoning',
                'OCR & Document Und.',
                'Chart & Diagram Und.',
                'Video Und.',
                'Cultural Specific Und.',
                'Medical Image Und.',
                'Agricultural Image Und.',
                'Remote Sensing Und.'
            ],
            type: 'pie',
            marker: {
                colors: [
                    '#f8d9e5', // Multimodal Und. & Reasoning
                    '#dfc8f0', // OCR and Document Und.
                    '#bbd7f4', // Chart and Diagram Und.
                    '#b5e1dd', // Video Und.
                    '#bde9ca', // Cultural Specific Und.
                    '#f5e6b3', // Medical Image Und.
                    '#f7d6b6', // Agricultural Image Und.
                    '#fde9c1'  // Remote Sensing Und.
                ]
            },
            //textinfo: 'label+percent',
            hoverinfo: 'label+percent',
            hoverlabel: {
                 bgcolor: [
                    '#f8d9e5', '#dfc8f0', '#bbd7f4',
                    '#b5e1dd', '#bde9ca', '#f5e6b3',
                    '#f7d6b6', '#fde9c1'
                ],
                font: {
                    color: 'gray'
                }
            }
        }];

        var pieLayout = {
            title: 'CAMEL-Bench Domains',
            height: 400,
            width: 600
        };

        Plotly.newPlot('pie-chart', pieData, pieLayout);

        // Data for Bar Charts (Placeholder)
        function generateBarData() {
            return [{
                x: ['A', 'B', 'C', 'D'],
                y: [10, 15, 13, 17],
                type: 'bar',
                marker: {
                    color: '#457b9d'
                }
            }];
        }

        var barLayout = {
            height: 300,
            width: 400,
            margin: {
                t: 30,
                b: 40
            }
        };

        // Generate 8 Bar Charts
        for (let i = 1; i <= 8; i++) {
            Plotly.newPlot('bar-chart-' + i, generateBarData(), barLayout);
        }
    </script>
</body>
</html>
